## Machine learning Diagnostics
##### Evaluating a learning algorithm

Split the data into three groups:

1. **Training set** used in training the model (Usually 60% of the dataset).
2. **Cross Validation set** used in selecting the hyperparameters with the lowest error (Usually 20% of the dataset).
3. **Test set** used in describing the generalized error as we can not report the error in the cross validation set because we chose the lowest error (Usually 20% of the dataset).

**Underfitting** is referred to as a model with **High bias**.

**Overfitting** is referred to as a model with **High variance**.

### Learning Curve

Plot of J<sub>test</sub>(Θ) error and J<sub>cv</sub>(Θ) error against train set size, from m = 1 to m.

##### Observations:

- J<sub>test</sub>(Θ) set will start low and increase when m increases as it is easy to fit low number of examples.
- J<sub>cv</sub>(Θ) will start high and decrease when m increases as the fitting gets better with high number of examples.
- High bias problem (underfitting) will occur when J<sub>test</sub>(Θ) and J<sub>cv</sub>(Θ) plateaus at a high error value
- When dealing with a high bias problem it will not help to get more training data.
- High variance problem (overfitting) will occur when there is a gap J<sub>test</sub>(Θ) and J<sub>cv</sub>(Θ) and they seem to be converging.
- When dealing with a high variance problem it will help to get more training data.
- If we have a large dataset and enough features that a human expert can predict the output using those features, then we can increase the complexity of the model without worrying about overfitting.

### Model Selection 

Hyperparameter tuning - A hyperparameter is a parameter whose value is set before the learning process begins.

Train multiple values of the hyperparameter and pick the model with the lowest test set error.
This can be used when:

- Choosing a polynomial degree
- Choosing lambda value

### Error analysis

Create a quick model with the first set of features that comes to mind, then look at the misclassifications to come up with a more sophisticated set of features.

### Skewed classes

Having a lot of data examples for one class and very few examples of the other class, this will result in reporting a very high accuracy despite the model being not representative.

Other evaluation metrics:

- **Precision** number of true positives / number of true positives + number of false positives<br>
Intuition - What proportion of positive identifications was actually correct?

- **Recall** number of true positives / number of true positives + number of false negatives<br>
Intuition - What proportion of actual positives was identified correctly?

Setting the threshold to a high number (&gt;0.5) will result in high precision and low recall which avoids high false positives.<br>
Setting the threshold to a low number (&lt;0.5) will result in low precision and high recall which avoids high false negatives.

**F-Score** - Combining Precision and recall = 2 * (P * R / P + R)

## Gradient Descent variations

**Batch gradient descent**

Each parameter gradient is using all the training examples in the dataset, with large datasets this might be inefficient.

**Stochastic gradient descent**<br>
1. Shuffle the dataset.
2. Update Θ<sup>J</sup> on example j only.

This is done for i = 1 to m.

This is useful for **online learning** as you are working with a stream of data that is coming one example at a time, Θ will improve after each example, and with enough examples over time, Θ will be minimized, this can also adapt to user preference changing over time because we are discarding an example after we train Θ with it.

**Mini Batch gradient descent**

Same as batch gradient descent but we use a smaller batch size B of examples in the dataset and we iterate updating Θ with each batch of examples.

This can be faster than stochastic gradient descent because of vectorization, but adds an extra paramater B to think about.

This can be useful with **Map / reduce and data parallelism** as we can make each computer or each core update Θ on different batches, and have a master computer that combines the updates to Θ, check third party libraries for multi-core processing which can be useful.

